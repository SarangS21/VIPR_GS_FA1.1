%% Create and Train a Deep Learning Model
% Script for creating and training a deep learning network with the following 
% properties:
%%
% 
%  Number of layers: 30
%  Number of connections: 31
%  Training setup file: /home/eceftl9/vipr/trainingSetup_2020_10_23__16_55_46.mat
%
%% 
% Run this script to create the network layers, import training and validation 
% data, and train the network. The network layers are stored in the workspace 
% variable |lgraph|. The trained network is stored in the workspace variable |net|.
% 
% To learn more, see <matlab:helpview('deeplearning','generate_matlab_code') 
% Generate MATLAB Code From Deep Network Designer>.
% 
% Auto-generated by MATLAB on 23-Oct-2020 16:55:53
%% Load Training Setup Data
% Load the data used to set up training. The training setup file contains the 
% parameters for network initialization and the training and validation data. 
% For transfer learning, the network initialization parameters are the parameters 
% of the initial pretrained network.

trainingSetup = load("/home/eceftl9/vipr/trainingSetup_2020_10_23__16_55_46.mat");
%% Import Data
% Import training and validation data.

dsTrain = trainingSetup.dsTrain;
dsValidation = trainingSetup.dsValidation;
%% Set Training Options
% Specify options to use when training.

opts = trainingOptions("sgdm",...
    "ExecutionEnvironment","auto",...
    "InitialLearnRate",0.05,...
    "MiniBatchSize",8,...
    'MaxEpochs',50, ...
    "Shuffle","every-epoch",...
    "Plots","training-progress",...
    "ValidationData",dsValidation);
%% Create Layer Graph
% Create the layer graph variable to contain the network layers.

lgraph = layerGraph();
%% Add Layer Branches
% Add the branches of the network to the layer graph. Each branch is a linear 
% array of layers.

tempLayers = [
    imageInputLayer([720 960 3],"Name","data","Normalization","none")
    nnet.resnet18.layer.ResNet18PreprocessingLayer("preprocessing")
    convolution2dLayer([7 7],64,"Name","conv1","BiasLearnRateFactor",0,"Padding",[3 3 3 3],"Stride",[2 2],"WeightsInitializer","narrow-normal","Bias",trainingSetup.conv1.Bias,"Weights",trainingSetup.conv1.Weights)
    batchNormalizationLayer("Name","bn_conv1","Offset",trainingSetup.bn_conv1.Offset,"Scale",trainingSetup.bn_conv1.Scale,"TrainedMean",trainingSetup.bn_conv1.TrainedMean,"TrainedVariance",trainingSetup.bn_conv1.TrainedVariance)
    reluLayer("Name","conv1_relu")
    maxPooling2dLayer([3 3],"Name","pool1","Padding",[1 1 1 1],"Stride",[2 2])];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([3 3],64,"Name","res2a_branch2a","BiasLearnRateFactor",0,"Padding",[1 1 1 1],"WeightsInitializer","narrow-normal","Bias",trainingSetup.res2a_branch2a.Bias,"Weights",trainingSetup.res2a_branch2a.Weights)
    batchNormalizationLayer("Name","bn2a_branch2a","Offset",trainingSetup.bn2a_branch2a.Offset,"Scale",trainingSetup.bn2a_branch2a.Scale,"TrainedMean",trainingSetup.bn2a_branch2a.TrainedMean,"TrainedVariance",trainingSetup.bn2a_branch2a.TrainedVariance)
    reluLayer("Name","res2a_branch2a_relu")
    convolution2dLayer([3 3],64,"Name","res2a_branch2b","BiasLearnRateFactor",0,"Padding",[1 1 1 1],"WeightsInitializer","narrow-normal","Bias",trainingSetup.res2a_branch2b.Bias,"Weights",trainingSetup.res2a_branch2b.Weights)
    batchNormalizationLayer("Name","bn2a_branch2b","Offset",trainingSetup.bn2a_branch2b.Offset,"Scale",trainingSetup.bn2a_branch2b.Scale,"TrainedMean",trainingSetup.bn2a_branch2b.TrainedMean,"TrainedVariance",trainingSetup.bn2a_branch2b.TrainedVariance)];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    additionLayer(2,"Name","res2a")
    reluLayer("Name","res2a_relu")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([3 3],64,"Name","res2b_branch2a","BiasLearnRateFactor",0,"Padding",[1 1 1 1],"WeightsInitializer","narrow-normal","Bias",trainingSetup.res2b_branch2a.Bias,"Weights",trainingSetup.res2b_branch2a.Weights)
    batchNormalizationLayer("Name","bn2b_branch2a","Offset",trainingSetup.bn2b_branch2a.Offset,"Scale",trainingSetup.bn2b_branch2a.Scale,"TrainedMean",trainingSetup.bn2b_branch2a.TrainedMean,"TrainedVariance",trainingSetup.bn2b_branch2a.TrainedVariance)
    reluLayer("Name","res2b_branch2a_relu")
    convolution2dLayer([3 3],64,"Name","res2b_branch2b","BiasLearnRateFactor",0,"Padding",[1 1 1 1],"WeightsInitializer","narrow-normal","Bias",trainingSetup.res2b_branch2b.Bias,"Weights",trainingSetup.res2b_branch2b.Weights)
    batchNormalizationLayer("Name","bn2b_branch2b","Offset",trainingSetup.bn2b_branch2b.Offset,"Scale",trainingSetup.bn2b_branch2b.Scale,"TrainedMean",trainingSetup.bn2b_branch2b.TrainedMean,"TrainedVariance",trainingSetup.bn2b_branch2b.TrainedVariance)];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    additionLayer(2,"Name","res2b")
    reluLayer("Name","res2b_relu")
    convolution2dLayer([3 3],256,"Name","conv","Padding","same")
    batchNormalizationLayer("Name","dec_bn3","Offset",trainingSetup.dec_bn3.Offset,"Scale",trainingSetup.dec_bn3.Scale,"TrainedMean",trainingSetup.dec_bn3.TrainedMean,"TrainedVariance",trainingSetup.dec_bn3.TrainedVariance)
    reluLayer("Name","dec_relu3")
    convolution2dLayer([3 3],256,"Name","dec_c4","BiasLearnRateFactor",0,"Padding","same","WeightLearnRateFactor",10,"Bias",trainingSetup.dec_c4.Bias,"Weights",trainingSetup.dec_c4.Weights)
    batchNormalizationLayer("Name","dec_bn4","Offset",trainingSetup.dec_bn4.Offset,"Scale",trainingSetup.dec_bn4.Scale,"TrainedMean",trainingSetup.dec_bn4.TrainedMean,"TrainedVariance",trainingSetup.dec_bn4.TrainedVariance)
    reluLayer("Name","dec_relu4")
    convolution2dLayer([1 1],11,"Name","scorer","BiasLearnRateFactor",0,"WeightLearnRateFactor",10,"Bias",trainingSetup.scorer.Bias,"Weights",trainingSetup.scorer.Weights)
    transposedConv2dLayer([8 8],6,"Name","transposed-conv","Cropping","same","Stride",[4 4])
    softmaxLayer("Name","softmax")
    pixelClassificationLayer("Name","pixel-class")];
lgraph = addLayers(lgraph,tempLayers);

% clean up helper variable
clear tempLayers;
%% Connect Layer Branches
% Connect all the branches of the network to create the network graph.

lgraph = connectLayers(lgraph,"pool1","res2a_branch2a");
lgraph = connectLayers(lgraph,"pool1","res2a/in2");
lgraph = connectLayers(lgraph,"bn2a_branch2b","res2a/in1");
lgraph = connectLayers(lgraph,"res2a_relu","res2b_branch2a");
lgraph = connectLayers(lgraph,"res2a_relu","res2b/in2");
lgraph = connectLayers(lgraph,"bn2b_branch2b","res2b/in1");
%% Train Network
% Train the network using the specified options and training data.

[netT, traininfo] = trainNetwork(dsTrain,lgraph,opts);